// API callback
Tabletop.singleton.loadSheet({"version":"1.0","encoding":"UTF-8","feed":{"xmlns":"http://www.w3.org/2005/Atom","xmlns$openSearch":"http://a9.com/-/spec/opensearchrss/1.0/","xmlns$gsx":"http://schemas.google.com/spreadsheets/2006/extended","id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"Fall_2010"},"link":[{"rel":"alternate","type":"text/html","href":"https://spreadsheets.google.com/pub?key\u003d0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc"},{"rel":"http://schemas.google.com/g/2005#feed","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values"},{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values?alt\u003djson-in-script\u0026sq\u003d"}],"author":[{"name":{"$t":"eric.e.monson"},"email":{"$t":"eric.e.monson@gmail.com"}}],"openSearch$totalResults":{"$t":"10"},"openSearch$startIndex":{"$t":"1"},"entry":[{"id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/cokwr"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"9/10/2010"},"content":{"type":"text","$t":"speaker: Rachael Brady \u0026 Todd Berreth, affiliation: Visualization Technology Group, title: Introducing the Gigapixel Navigator, abstract: Image stitching software has enabled the creation of Gigapixel images which are truly amazing (see Gigapan.org). The DISP group at Duke is creating a camera which can take a Gigapixel image in one shot. The existance of these kind of images creates the need for a viewer with fast and easy pan and zoom functionality. This talk will present The Gigapixel Navitagor; a Gigapixel viewer that is designed for the Tiled Wall at the Link. The program will work for any image in size up to 200 GigaPixels. A person can pan around and zoom into the image through an iPOD application. This talk will describe the architecture of the tiled wall, the design of the image viewer, the software used, and demonstrate it's capabilities."},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/cokwr"}],"gsx$date":{"$t":"9/10/2010"},"gsx$speaker":{"$t":"Rachael Brady \u0026 Todd Berreth"},"gsx$affiliation":{"$t":"Visualization Technology Group"},"gsx$title":{"$t":"Introducing the Gigapixel Navigator"},"gsx$abstract":{"$t":"Image stitching software has enabled the creation of Gigapixel images which are truly amazing (see Gigapan.org). The DISP group at Duke is creating a camera which can take a Gigapixel image in one shot. The existance of these kind of images creates the need for a viewer with fast and easy pan and zoom functionality. This talk will present The Gigapixel Navitagor; a Gigapixel viewer that is designed for the Tiled Wall at the Link. The program will work for any image in size up to 200 GigaPixels. A person can pan around and zoom into the image through an iPOD application. This talk will describe the architecture of the tiled wall, the design of the image viewer, the software used, and demonstrate it's capabilities."},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/cpzh4"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"9/17/2010"},"content":{"type":"text","$t":"speaker: Felice Frankel, affiliation: Harvard Medical School \u0026 MIT, title: Picturing to Learn: A New Approach to Finding Students Misconceptions in Science Education., abstract: During the four-year NSF-funded Picturing to Learn program, we collected over 3000 drawings from 1100 undergraduate college students. Teachers (literally) saw their students’ misconceptions, which then informed adjustments in their instructional approaches. In addition, through a series of collaborative workshops for teachers and, separately, for students, we developed an exciting and innovative “venue” for learning and teaching, deepening their understanding of science. This talk will describe our findings and engage the audience in conversation to discuss the potential of expanding the program to graduate students and to middle and high school students."},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/cpzh4"}],"gsx$date":{"$t":"9/17/2010"},"gsx$speaker":{"$t":"Felice Frankel"},"gsx$affiliation":{"$t":"Harvard Medical School \u0026 MIT"},"gsx$title":{"$t":"Picturing to Learn: A New Approach to Finding Students Misconceptions in Science Education."},"gsx$abstract":{"$t":"During the four-year NSF-funded Picturing to Learn program, we collected over 3000 drawings from 1100 undergraduate college students. Teachers (literally) saw their students’ misconceptions, which then informed adjustments in their instructional approaches. In addition, through a series of collaborative workshops for teachers and, separately, for students, we developed an exciting and innovative “venue” for learning and teaching, deepening their understanding of science. This talk will describe our findings and engage the audience in conversation to discuss the potential of expanding the program to graduate students and to middle and high school students."},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/cre1l"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"10/1/2010"},"content":{"type":"text","$t":"speaker: Eric Monson and Mauro Maggioni, affiliation: Visualization Technology Group and Mathematics, title: Data Representation and Exploration with Geometric Wavelets, abstract: Geometric Wavelets is a new multi-scale data representation technique which is useful for a variety of applications such as data compression, interpretation and anomaly detection. We have developed an interactive visualization with multiple linked views to help users quickly explore data sets and understand this novel construction. Currently the interface is being used by applied mathematicians to view results and gain new insights, speeding methods development. Joint work with Guangliang Chen and Rachael Brady"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/cre1l"}],"gsx$date":{"$t":"10/1/2010"},"gsx$speaker":{"$t":"Eric Monson and Mauro Maggioni"},"gsx$affiliation":{"$t":"Visualization Technology Group and Mathematics"},"gsx$title":{"$t":"Data Representation and Exploration with Geometric Wavelets"},"gsx$abstract":{"$t":"Geometric Wavelets is a new multi-scale data representation technique which is useful for a variety of applications such as data compression, interpretation and anomaly detection. We have developed an interactive visualization with multiple linked views to help users quickly explore data sets and understand this novel construction. Currently the interface is being used by applied mathematicians to view results and gain new insights, speeding methods development. Joint work with Guangliang Chen and Rachael Brady"},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/chk2m"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"10/8/2010"},"content":{"type":"text","$t":"speaker: Amy Caron, affiliation: Duke Visiting Artist, title: Mental pictures, Creative Hallucinations, and Hard Science - how I communicate the invisible to the world, abstract: In this lecture, I will discuss my approach to visualization techniques through my three current art projects; one connected to neuroscience, one connected to algae, and one exploring the concept of commitment. I will discuss how a creative perspective and capacity for divergent and convergent thinking mingle with research to form a unique form of communication. Amy has an installation in the CIEMAS Studio that's open Oct 19, 2010 - Oct 30, 2010. She is also doing eight performances. Go to the DIBS website to for more information."},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/chk2m"}],"gsx$date":{"$t":"10/8/2010"},"gsx$speaker":{"$t":"Amy Caron"},"gsx$affiliation":{"$t":"Duke Visiting Artist"},"gsx$title":{"$t":"Mental pictures, Creative Hallucinations, and Hard Science - how I communicate the invisible to the world"},"gsx$abstract":{"$t":"In this lecture, I will discuss my approach to visualization techniques through my three current art projects; one connected to neuroscience, one connected to algae, and one exploring the concept of commitment. I will discuss how a creative perspective and capacity for divergent and convergent thinking mingle with research to form a unique form of communication. Amy has an installation in the CIEMAS Studio that's open Oct 19, 2010 - Oct 30, 2010. She is also doing eight performances. Go to the DIBS website to for more information."},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/ciyn3"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"10/15/2010"},"content":{"type":"text","$t":"speaker: Sarah Cohen, affiliation: Sanford School of Public Policy, title: Vis in News: The hidden agenda, abstract: Visualizations in print and online news publications carry many burdens: removing technical information from prose, providing transparency in the reporting, telling a story, logging facts about long-running stories and keeping users on a site. They also carry extra work on the part of cash-strapped news organizations because the most successful ones rarely start with already-compiled data. This talk will provide some examples of news visualizations, their purposes and the reasons they may or may not have succeeded."},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/ciyn3"}],"gsx$date":{"$t":"10/15/2010"},"gsx$speaker":{"$t":"Sarah Cohen"},"gsx$affiliation":{"$t":"Sanford School of Public Policy"},"gsx$title":{"$t":"Vis in News: The hidden agenda"},"gsx$abstract":{"$t":"Visualizations in print and online news publications carry many burdens: removing technical information from prose, providing transparency in the reporting, telling a story, logging facts about long-running stories and keeping users on a site. They also carry extra work on the part of cash-strapped news organizations because the most successful ones rarely start with already-compiled data. This talk will provide some examples of news visualizations, their purposes and the reasons they may or may not have succeeded."},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/ckd7g"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"10/22/2010"},"content":{"type":"text","$t":"speaker: Eero Simoncelli, affiliation: Center for Neural Science and Courant Inst. of Mathematical Sciences, New York University, title: Characterization of neural response with stochastic stimuli, abstract: A fundamental goal of sensory systems neuroscience is the characterization of the functional relationship between environmental stimuli and neural response. In seeking computational models that can be used for this purpose, there is a natural tradeoff between biological realism and computational simplicity/tractability. I'll describe several solutions that inherit much of the simplicity and computational advantage of linear systems, and yet are capable of faithfully reproducing many of the complexities of spiking neural responses. I'll discuss application of these methods to visual neurons in retina and visual cortex."},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/ckd7g"}],"gsx$date":{"$t":"10/22/2010"},"gsx$speaker":{"$t":"Eero Simoncelli"},"gsx$affiliation":{"$t":"Center for Neural Science and Courant Inst. of Mathematical Sciences, New York University"},"gsx$title":{"$t":"Characterization of neural response with stochastic stimuli"},"gsx$abstract":{"$t":"A fundamental goal of sensory systems neuroscience is the characterization of the functional relationship between environmental stimuli and neural response. In seeking computational models that can be used for this purpose, there is a natural tradeoff between biological realism and computational simplicity/tractability. I'll describe several solutions that inherit much of the simplicity and computational advantage of linear systems, and yet are capable of faithfully reproducing many of the complexities of spiking neural responses. I'll discuss application of these methods to visual neurons in retina and visual cortex."},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/clrrx"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"11/5/2010"},"content":{"type":"text","$t":"speaker: Jie Ren, affiliation: Physics, title: Looking into Granular Systems, abstract: Why can we stand on sand without sinking? When considered individually, sand grains only interact through contact forces, but when considered as a large assembly, sand behavior is quite complicated. In a pile of sand, these simple contact forces form large-scale networks and change collectively in response to external environments. However, this network, though very essential for understanding granular systems, is very hard to observe. In our study, we apply a unique visualization method to a model system with particles made of photo-elastic material and for the first time we are able to observe this intrinsic force network in real experiments. In my talk I will introduce the principle of photo-elasticity, the experimental method to visualize the force network, and describe the algorithm used to calculate the real contact forces from the pictures taken. I will also present some of our results to give an idea of where we can go from these experiments."},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/clrrx"}],"gsx$date":{"$t":"11/5/2010"},"gsx$speaker":{"$t":"Jie Ren"},"gsx$affiliation":{"$t":"Physics"},"gsx$title":{"$t":"Looking into Granular Systems"},"gsx$abstract":{"$t":"Why can we stand on sand without sinking? When considered individually, sand grains only interact through contact forces, but when considered as a large assembly, sand behavior is quite complicated. In a pile of sand, these simple contact forces form large-scale networks and change collectively in response to external environments. However, this network, though very essential for understanding granular systems, is very hard to observe. In our study, we apply a unique visualization method to a model system with particles made of photo-elastic material and for the first time we are able to observe this intrinsic force network in real experiments. In my talk I will introduce the principle of photo-elasticity, the experimental method to visualize the force network, and describe the algorithm used to calculate the real contact forces from the pictures taken. I will also present some of our results to give an idea of where we can go from these experiments."},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/cyevm"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"11/12/2010"},"content":{"type":"text","$t":"speaker: Robert Kosara, affiliation: Computer Science, UNC Charlotte, title: A Bit of Science for InfoVis, abstract: Most work in information visualization (InfoVis) today is focused on building new systems and developing new techniques, while introspection and the building of theory is not receiving a lot of attention. In this talk, I will present some recent results from studies that question some of the common assumptions made in InfoVis, and make the case for a new focus on theory and scientific rigor."},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/cyevm"}],"gsx$date":{"$t":"11/12/2010"},"gsx$speaker":{"$t":"Robert Kosara"},"gsx$affiliation":{"$t":"Computer Science, UNC Charlotte"},"gsx$title":{"$t":"A Bit of Science for InfoVis"},"gsx$abstract":{"$t":"Most work in information visualization (InfoVis) today is focused on building new systems and developing new techniques, while introspection and the building of theory is not receiving a lot of attention. In this talk, I will present some recent results from studies that question some of the common assumptions made in InfoVis, and make the case for a new focus on theory and scientific rigor."},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/cztg3"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"11/19/2010"},"content":{"type":"text","$t":"speaker: Ryan McMahan, affiliation: Computer Science, Virginia Tech, title: Exploring the Effects of Display Fidelity and Interaction Fidelity for Serious Virtual Reality Game, abstract: Despite contrasting levels of display fidelity and interaction fidelity, virtual reality (VR) systems and video games have both been successfully used for non-entertainment purposes, such as education, training, and therapy. The goal of this research was to distinctly evaluate display fidelity and interaction fidelity for a serious VR game to determine the effects of and interactions between these two fidelities. Using the DiVE, we designed and conducted a 2 (low display-fidelity, high display-fidelity) by 2 (low interaction-fidelity, high interaction-fidelity) within-subject experiment based on objective user performances and subjective user responses."},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/cztg3"}],"gsx$date":{"$t":"11/19/2010"},"gsx$speaker":{"$t":"Ryan McMahan"},"gsx$affiliation":{"$t":"Computer Science, Virginia Tech"},"gsx$title":{"$t":"Exploring the Effects of Display Fidelity and Interaction Fidelity for Serious Virtual Reality Game"},"gsx$abstract":{"$t":"Despite contrasting levels of display fidelity and interaction fidelity, virtual reality (VR) systems and video games have both been successfully used for non-entertainment purposes, such as education, training, and therapy. The goal of this research was to distinctly evaluate display fidelity and interaction fidelity for a serious VR game to determine the effects of and interactions between these two fidelities. Using the DiVE, we designed and conducted a 2 (low display-fidelity, high display-fidelity) by 2 (low interaction-fidelity, high interaction-fidelity) within-subject experiment based on objective user performances and subjective user responses."},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/d180g"},"updated":{"$t":"2015-01-21T14:57:47.197Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"12/3/2010"},"content":{"type":"text","$t":"speaker: Pat Halpin, Jesse Cleary and Ben Donnelly, affiliation: Marine Geospatial Ecology Lab, Nicholas School of the Environment, title: Visualizing Ocean Life, abstract: How do you fit the work of 2700 scientists into 17.5 square feet? Pat Halpin's lab at the Nicholas School of the Environment has been the visualization hub for Census of Marine Life, a decade-long international effort to assess the biodiversity of the ocean. Their most high-profile visualization for the Census was a double-sided poster produced with National Geographic Maps. The lab will discuss the process of coaxing out broad themes from dozens of research publications, and making those themes accessible a general audience. An online version of the map can be explored here (http://comlmaps.org/oceanlifemap)"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/0AgpG-BX4vPChdGdQdGllSEc1eDlTMjl5NUZjWVdnTHc/ocx/public/values/d180g"}],"gsx$date":{"$t":"12/3/2010"},"gsx$speaker":{"$t":"Pat Halpin, Jesse Cleary and Ben Donnelly"},"gsx$affiliation":{"$t":"Marine Geospatial Ecology Lab, Nicholas School of the Environment"},"gsx$title":{"$t":"Visualizing Ocean Life"},"gsx$abstract":{"$t":"How do you fit the work of 2700 scientists into 17.5 square feet? Pat Halpin's lab at the Nicholas School of the Environment has been the visualization hub for Census of Marine Life, a decade-long international effort to assess the biodiversity of the ocean. Their most high-profile visualization for the Census was a double-sided poster produced with National Geographic Maps. The lab will discuss the process of coaxing out broad themes from dozens of research publications, and making those themes accessible a general audience. An online version of the map can be explored here (http://comlmaps.org/oceanlifemap)"},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""}}]}});
// API callback
Tabletop.singleton.loadSheet({"version":"1.0","encoding":"UTF-8","feed":{"xmlns":"http://www.w3.org/2005/Atom","xmlns$openSearch":"http://a9.com/-/spec/opensearchrss/1.0/","xmlns$gsx":"http://schemas.google.com/spreadsheets/2006/extended","id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"Fall_2014"},"link":[{"rel":"alternate","type":"application/atom+xml","href":"https://docs.google.com/spreadsheets/d/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/pubhtml"},{"rel":"http://schemas.google.com/g/2005#feed","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values"},{"rel":"http://schemas.google.com/g/2005#post","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values"},{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values?alt\u003djson-in-script"}],"author":[{"name":{"$t":"eric.e.monson"},"email":{"$t":"eric.e.monson@gmail.com"}}],"openSearch$totalResults":{"$t":"14"},"openSearch$startIndex":{"$t":"1"},"entry":[{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cokwr"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"9/5/2014"},"content":{"type":"text","$t":"speaker: Tim Stallmann, affiliation: Freelance map maker \u0026 teacher at the Duke Center for Documentary Studies, title: Using maps to ask questions \u0026 make change, abstract: Like many visual forms, maps have a complicated history – sometimes they're used as tools of domination and oppression, other times as ways to build a more just society. As a cartographer, trying to follow the side of the line which bends towards justice is not always easy. Counter-cartography advocates making maps that ask questions more than they answer them, in an attempt to unseat dominant spatial patterns and ways of thinking. This talk will present a few case studies of counter-mapping projects I've been involved with, both as a member of the 3Cs Counter-Cartographies Collective and as a freelance map-maker. I'll walk through some of the techniques I've used (both high and low-tech), and some of the difficult (and often unanswered) questions that come up in trying to do mapping as part of social justice work., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dc3ed2973-fc28-4f35-86dd-2389ec4afc4b, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dc3ed2973-fc28-4f35-86dd-2389ec4afc4b"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cokwr"}],"gsx$date":{"$t":"9/5/2014"},"gsx$speaker":{"$t":"Tim Stallmann"},"gsx$affiliation":{"$t":"Freelance map maker \u0026 teacher at the Duke Center for Documentary Studies"},"gsx$title":{"$t":"Using maps to ask questions \u0026 make change"},"gsx$abstract":{"$t":"Like many visual forms, maps have a complicated history – sometimes they're used as tools of domination and oppression, other times as ways to build a more just society. As a cartographer, trying to follow the side of the line which bends towards justice is not always easy. Counter-cartography advocates making maps that ask questions more than they answer them, in an attempt to unseat dominant spatial patterns and ways of thinking. This talk will present a few case studies of counter-mapping projects I've been involved with, both as a member of the 3Cs Counter-Cartographies Collective and as a freelance map-maker. I'll walk through some of the techniques I've used (both high and low-tech), and some of the difficult (and often unanswered) questions that come up in trying to do mapping as part of social justice work."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dc3ed2973-fc28-4f35-86dd-2389ec4afc4b"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dc3ed2973-fc28-4f35-86dd-2389ec4afc4b"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cpzh4"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"9/12/2014"},"content":{"type":"text","$t":"speaker: Diego V Bohórquez, affiliation: Duke Medical Center, title: Visualizing the food-sensing biosensors of our gut, abstract: Our brain is fed with sensory information from food in our gut through specialized biosensors called enteroendocrine cells. For a long time these cells have been assumed to communicate with nerves indirectly through hormones. The primary reason is that they are difficult to identify and a complete description of their anatomy is lacking. Here we develop a method to correlate confocal microscopy with serial block face scanning electron microscopy and document the entire ultrastructure of a specific enteroendocrine cell. Using manual segmentation and volume rendering, we uncovered in enteroendocrine cells a prominent neuropod – the missing link to nerves carrying sensory information to the brain., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d13820158-4a00-41ad-b351-4547aeb6840f, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d13820158-4a00-41ad-b351-4547aeb6840f"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cpzh4"}],"gsx$date":{"$t":"9/12/2014"},"gsx$speaker":{"$t":"Diego V Bohórquez"},"gsx$affiliation":{"$t":"Duke Medical Center"},"gsx$title":{"$t":"Visualizing the food-sensing biosensors of our gut"},"gsx$abstract":{"$t":"Our brain is fed with sensory information from food in our gut through specialized biosensors called enteroendocrine cells. For a long time these cells have been assumed to communicate with nerves indirectly through hormones. The primary reason is that they are difficult to identify and a complete description of their anatomy is lacking. Here we develop a method to correlate confocal microscopy with serial block face scanning electron microscopy and document the entire ultrastructure of a specific enteroendocrine cell. Using manual segmentation and volume rendering, we uncovered in enteroendocrine cells a prominent neuropod – the missing link to nerves carrying sensory information to the brain."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d13820158-4a00-41ad-b351-4547aeb6840f"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d13820158-4a00-41ad-b351-4547aeb6840f"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cre1l"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"9/19/2014"},"content":{"type":"text","$t":"speaker: Olexandr Isayev, affiliation: Division of Chemical Biology and Medicinal Chemistry, UNC-CH School of Pharmacy, title: \"Big chemical data\" visualization: from simple molecules to complex networks, abstract: Chemistry and most STEM disciplines are rapidly changing to data driven sciences. The explosive rate of data generation is providing incredible opportunities for research, with the potential to transform our current practices. The exploitation of so-called \"big data\" will enable us to undertake research projects never previously possible but should also stimulate a re-evaluation of all our data practices. Furthermore, data visualization has the potential to improve decision-making, uncover the meaningful relationships and patterns in available data. In this introductory lecture, I will overview emerging trends in chemical visualization and survey examples from industry leaders as well as our own lab., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003df9ee15a0-1918-47a1-b80c-432b567575c7, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003df9ee15a0-1918-47a1-b80c-432b567575c7"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cre1l"}],"gsx$date":{"$t":"9/19/2014"},"gsx$speaker":{"$t":"Olexandr Isayev"},"gsx$affiliation":{"$t":"Division of Chemical Biology and Medicinal Chemistry, UNC-CH School of Pharmacy"},"gsx$title":{"$t":"\"Big chemical data\" visualization: from simple molecules to complex networks"},"gsx$abstract":{"$t":"Chemistry and most STEM disciplines are rapidly changing to data driven sciences. The explosive rate of data generation is providing incredible opportunities for research, with the potential to transform our current practices. The exploitation of so-called \"big data\" will enable us to undertake research projects never previously possible but should also stimulate a re-evaluation of all our data practices. Furthermore, data visualization has the potential to improve decision-making, uncover the meaningful relationships and patterns in available data. In this introductory lecture, I will overview emerging trends in chemical visualization and survey examples from industry leaders as well as our own lab."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003df9ee15a0-1918-47a1-b80c-432b567575c7"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003df9ee15a0-1918-47a1-b80c-432b567575c7"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/chk2m"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"9/26/2014"},"content":{"type":"text","$t":"speaker: Julien Finet, affiliation: Kitware, Inc, title: 3D Slicer, an open-source software framework for visualization and image analysis, abstract: 3D Slicer is a free, open source software package for image analysis and scientific visualization that is partially funded by NA-MIC and supported by a very large community. We will briefly present the variety of research areas and introduce the application using driving biological problems. We will also present how Slicer can be extended to facilitate research and speed-up development., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003de98a6b99-80e8-4c4c-9fe5-acd507eed447, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003de98a6b99-80e8-4c4c-9fe5-acd507eed447"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/chk2m"}],"gsx$date":{"$t":"9/26/2014"},"gsx$speaker":{"$t":"Julien Finet"},"gsx$affiliation":{"$t":"Kitware, Inc"},"gsx$title":{"$t":"3D Slicer, an open-source software framework for visualization and image analysis"},"gsx$abstract":{"$t":"3D Slicer is a free, open source software package for image analysis and scientific visualization that is partially funded by NA-MIC and supported by a very large community. We will briefly present the variety of research areas and introduce the application using driving biological problems. We will also present how Slicer can be extended to facilitate research and speed-up development."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003de98a6b99-80e8-4c4c-9fe5-acd507eed447"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003de98a6b99-80e8-4c4c-9fe5-acd507eed447"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/ciyn3"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"10/3/2014"},"content":{"type":"text","$t":"speaker: Marco Toledo Bastos, affiliation: HASTAC, title: Bridging Structural Holes in Scholarly Social Networks, abstract: In this talk we explore the interplay between user activity in the scholarly social network HASTAC and the academic output of HASTAC Scholars. We relied on quantitative data collected from the publicly-accessible scholarly social network HASTAC and qualitative data collected from a survey of 123 students and recent alumni of the HASTAC Scholars Program. We explore a series of visualizations of the HASTAC network to show that Scholars who both collaborated online and published their academic work together bridge structural holes in the network. Lastly, we discuss the preliminary results of our study that tested the hypothesis that the activity of users on academic social networks is associated with academic output., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d46c9cc65-7fe4-4c21-812d-a41ad21a5769, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d46c9cc65-7fe4-4c21-812d-a41ad21a5769"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/ciyn3"}],"gsx$date":{"$t":"10/3/2014"},"gsx$speaker":{"$t":"Marco Toledo Bastos"},"gsx$affiliation":{"$t":"HASTAC"},"gsx$title":{"$t":"Bridging Structural Holes in Scholarly Social Networks"},"gsx$abstract":{"$t":"In this talk we explore the interplay between user activity in the scholarly social network HASTAC and the academic output of HASTAC Scholars. We relied on quantitative data collected from the publicly-accessible scholarly social network HASTAC and qualitative data collected from a survey of 123 students and recent alumni of the HASTAC Scholars Program. We explore a series of visualizations of the HASTAC network to show that Scholars who both collaborated online and published their academic work together bridge structural holes in the network. Lastly, we discuss the preliminary results of our study that tested the hypothesis that the activity of users on academic social networks is associated with academic output."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d46c9cc65-7fe4-4c21-812d-a41ad21a5769"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d46c9cc65-7fe4-4c21-812d-a41ad21a5769"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/ckd7g"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"10/10/2014"},"content":{"type":"text","$t":"speaker: Stephen Toback, affiliation: Duke Office of Information Technology, title: Stereographic 3D Video Capture \u0026 Display Technologies, abstract: Steve Toback, Senior Manager for OIT's Interactive Technology Services group will be presenting on the state of capture and display of stereographic 3D images. The consumerization of 3D \u200brecording and display technologies have lowered the entry point for recording this technology but 3D glasses still remain a barrier for wider adoption. Steve will be demonstrating a revolutionary new glasses free 3D display that has been under development by Dolby Labs, Dimenco and Philips and is now commercially available., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d042837ed-1ecc-471c-b135-e0017fbf0116, videonotes: Slides not captured directly, but they show up very well in the video., livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d042837ed-1ecc-471c-b135-e0017fbf0116"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/ckd7g"}],"gsx$date":{"$t":"10/10/2014"},"gsx$speaker":{"$t":"Stephen Toback"},"gsx$affiliation":{"$t":"Duke Office of Information Technology"},"gsx$title":{"$t":"Stereographic 3D Video Capture \u0026 Display Technologies"},"gsx$abstract":{"$t":"Steve Toback, Senior Manager for OIT's Interactive Technology Services group will be presenting on the state of capture and display of stereographic 3D images. The consumerization of 3D \u200brecording and display technologies have lowered the entry point for recording this technology but 3D glasses still remain a barrier for wider adoption. Steve will be demonstrating a revolutionary new glasses free 3D display that has been under development by Dolby Labs, Dimenco and Philips and is now commercially available."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d042837ed-1ecc-471c-b135-e0017fbf0116"},"gsx$videonotes":{"$t":"Slides not captured directly, but they show up very well in the video."},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d042837ed-1ecc-471c-b135-e0017fbf0116"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/clrrx"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"10/17/2014"},"content":{"type":"text","$t":"speaker: No talk, affiliation: Fall Break"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/clrrx"}],"gsx$date":{"$t":"10/17/2014"},"gsx$speaker":{"$t":"No talk"},"gsx$affiliation":{"$t":"Fall Break"},"gsx$title":{"$t":""},"gsx$abstract":{"$t":""},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cyevm"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"10/24/2014"},"content":{"type":"text","$t":"speaker: Angela Zoss, affiliation: Duke University Libraries, Research Computing, title: Text-based disease classification of medical literature, abstract: In a recent collaboration with researchers from Indiana University, I have begun exploring ways to use natural language terms and phrases to detect broad disease categories in the titles of articles from the PubMed database.  An early attempt classifies four million papers written in five different languages over the last 50 years into nine broad disease categories, visualizing the results as flows and streams to explore the changing focus of medical research over time. This early project was submitted as an entry to the ACM Web Science 2014 Conference, where it received an award as a top student submission. Future work includes refining disease detection with more sophisticated text and data mining, as well as developing new visual interfaces to the results. , video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003da69f9d90-1b38-42e3-82ab-9c93d7eeab33, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003da69f9d90-1b38-42e3-82ab-9c93d7eeab33"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cyevm"}],"gsx$date":{"$t":"10/24/2014"},"gsx$speaker":{"$t":"Angela Zoss"},"gsx$affiliation":{"$t":"Duke University Libraries, Research Computing"},"gsx$title":{"$t":"Text-based disease classification of medical literature"},"gsx$abstract":{"$t":"In a recent collaboration with researchers from Indiana University, I have begun exploring ways to use natural language terms and phrases to detect broad disease categories in the titles of articles from the PubMed database.  An early attempt classifies four million papers written in five different languages over the last 50 years into nine broad disease categories, visualizing the results as flows and streams to explore the changing focus of medical research over time. This early project was submitted as an entry to the ACM Web Science 2014 Conference, where it received an award as a top student submission. Future work includes refining disease detection with more sophisticated text and data mining, as well as developing new visual interfaces to the results. "},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003da69f9d90-1b38-42e3-82ab-9c93d7eeab33"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003da69f9d90-1b38-42e3-82ab-9c93d7eeab33"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cztg3"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"10/31/2014"},"content":{"type":"text","$t":"speaker: Victoria Szabo, affiliation: Duke ISIS, MA+S, title: Augmented Humanities Practice: The Fluid Site of Annotation , abstract: This paper explores the implications of location-based and marker-based augmented reality for creative digital humanities practice in the public sphere. I will focus on augmented reality systems as a way to place historical and cultural annotations in real-time dialogue with the lived experience of real-world spaces, places, and objects. I will show how digital heritage AR projects draw upon traditional approaches to annotating and representing urban places and built artifacts, as well as from contemporary digital mapping, multimedia production techniques, and virtual worlds and games. I’ll touch of each of these areas in turn as part of an investigation of this emergent \"medium\" of expression, drawing upon collaborative case-study projects focused in Venice, Italy; Durham, North Carolina; and Barcelona, Spain. I will also touch upon the concept of the augmented reality marker as a fluid site of annotation, and, in the wake of enhanced computer vision and ubiquitous computing, the implications for markerless annotation systems., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dd466a87e-4213-4845-ae6d-f667e383caa3, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dd466a87e-4213-4845-ae6d-f667e383caa3"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cztg3"}],"gsx$date":{"$t":"10/31/2014"},"gsx$speaker":{"$t":"Victoria Szabo"},"gsx$affiliation":{"$t":"Duke ISIS, MA+S"},"gsx$title":{"$t":"Augmented Humanities Practice: The Fluid Site of Annotation "},"gsx$abstract":{"$t":"This paper explores the implications of location-based and marker-based augmented reality for creative digital humanities practice in the public sphere. I will focus on augmented reality systems as a way to place historical and cultural annotations in real-time dialogue with the lived experience of real-world spaces, places, and objects. I will show how digital heritage AR projects draw upon traditional approaches to annotating and representing urban places and built artifacts, as well as from contemporary digital mapping, multimedia production techniques, and virtual worlds and games. I’ll touch of each of these areas in turn as part of an investigation of this emergent \"medium\" of expression, drawing upon collaborative case-study projects focused in Venice, Italy; Durham, North Carolina; and Barcelona, Spain. I will also touch upon the concept of the augmented reality marker as a fluid site of annotation, and, in the wake of enhanced computer vision and ubiquitous computing, the implications for markerless annotation systems."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dd466a87e-4213-4845-ae6d-f667e383caa3"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dd466a87e-4213-4845-ae6d-f667e383caa3"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/d180g"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"11/7/2014"},"content":{"type":"text","$t":"speaker: Philip B. White, affiliation: Data and Visualization Services, UNCG, title: Using Maps as an Interactive Presentation Tool, abstract: I am going to discuss the emergence of the \"story map\" as a popular tool for presenting a story. Story maps often present images, videos, and other multimedia content referenced to locations on a map. I will demonstrate different methods of presenting stories alongside maps using examples from current events. I will also touch upon the latest trends in online mapping, identify some best practices, and discuss what makes a web-map relevant., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dddc38e9d-b753-477a-8562-ed5db083f345, videonotes: There was a problem with the recording equipment, so the slides weren't captured, but you can still see them fairly well in the video., slides: slides/WhitePB_FridayViz_11_7_14.pdf, slidesnotes: Relevant links: \u003ca href\u003d\"http://dukeuniv.maps.arcgis.com/apps/MapJournal/?appid\u003d9304c0c18d1347a08d806e302915bf64\"\u003eBurnsides Expedition\u003c/a\u003e, \u003ca href\u003d\"http://dukeuniv.maps.arcgis.com/apps/StorytellingSwipe/?appid\u003d4416684e0cb44a59a6d143af57ab5a8e\"\u003eCongressional District Slider Map\u003c/a\u003e, \u003ca href\u003d\"http://dukeuniv.maps.arcgis.com/apps/Viewer/index.html?appid\u003d01b2ef55aa8e4ea3b7ce33df2e21229a\"\u003eCongressional Map with population density and diversity index\u003c/a\u003e, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dddc38e9d-b753-477a-8562-ed5db083f345"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/d180g"}],"gsx$date":{"$t":"11/7/2014"},"gsx$speaker":{"$t":"Philip B. White"},"gsx$affiliation":{"$t":"Data and Visualization Services, UNCG"},"gsx$title":{"$t":"Using Maps as an Interactive Presentation Tool"},"gsx$abstract":{"$t":"I am going to discuss the emergence of the \"story map\" as a popular tool for presenting a story. Story maps often present images, videos, and other multimedia content referenced to locations on a map. I will demonstrate different methods of presenting stories alongside maps using examples from current events. I will also touch upon the latest trends in online mapping, identify some best practices, and discuss what makes a web-map relevant."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dddc38e9d-b753-477a-8562-ed5db083f345"},"gsx$videonotes":{"$t":"There was a problem with the recording equipment, so the slides weren't captured, but you can still see them fairly well in the video."},"gsx$slides":{"$t":"slides/WhitePB_FridayViz_11_7_14.pdf"},"gsx$slidesnotes":{"$t":"Relevant links: \u003ca href\u003d\"http://dukeuniv.maps.arcgis.com/apps/MapJournal/?appid\u003d9304c0c18d1347a08d806e302915bf64\"\u003eBurnsides Expedition\u003c/a\u003e, \u003ca href\u003d\"http://dukeuniv.maps.arcgis.com/apps/StorytellingSwipe/?appid\u003d4416684e0cb44a59a6d143af57ab5a8e\"\u003eCongressional District Slider Map\u003c/a\u003e, \u003ca href\u003d\"http://dukeuniv.maps.arcgis.com/apps/Viewer/index.html?appid\u003d01b2ef55aa8e4ea3b7ce33df2e21229a\"\u003eCongressional Map with population density and diversity index\u003c/a\u003e"},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dddc38e9d-b753-477a-8562-ed5db083f345"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/d2mkx"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"11/14/2014"},"content":{"type":"text","$t":"speaker: Mike Nutt, affiliation: NCSU Libraries, title: The Hunt Library: A Storytelling Building, abstract: Almost 800 square feet of pixel space is integrated into the architecture throughout the James B. Hunt Jr. Library. This combination of digital media and physical space allows for new kinds of communication that augment visualizations with the corporeal qualities humans love: closeness, touch, immediacy, movement, and face-to-face conversation. While these large-scale visualization spaces promise to facilitate new approaches to the traditional research process, it will take time and effort to figure out the best way to utilize their abilities in the research workflow. As we explore those possibilities, the NCSU Libraries has also pursued a strategy that focuses on using our video walls for public engagement and scholarly communication through visual storytelling. As a result, visitors to the Hunt Library use our video walls to learn about what is happening on their campus and around the world. In this talk, you will see and hear stories from our storytelling building, and we will discuss some of the challenges and opportunities involved in creating a permanent portfolio of content for public video walls that is crowdsourced from a campus community., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d5e1b2985-28cc-4f55-8def-2591f07c6110, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d5e1b2985-28cc-4f55-8def-2591f07c6110"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/d2mkx"}],"gsx$date":{"$t":"11/14/2014"},"gsx$speaker":{"$t":"Mike Nutt"},"gsx$affiliation":{"$t":"NCSU Libraries"},"gsx$title":{"$t":"The Hunt Library: A Storytelling Building"},"gsx$abstract":{"$t":"Almost 800 square feet of pixel space is integrated into the architecture throughout the James B. Hunt Jr. Library. This combination of digital media and physical space allows for new kinds of communication that augment visualizations with the corporeal qualities humans love: closeness, touch, immediacy, movement, and face-to-face conversation. While these large-scale visualization spaces promise to facilitate new approaches to the traditional research process, it will take time and effort to figure out the best way to utilize their abilities in the research workflow. As we explore those possibilities, the NCSU Libraries has also pursued a strategy that focuses on using our video walls for public engagement and scholarly communication through visual storytelling. As a result, visitors to the Hunt Library use our video walls to learn about what is happening on their campus and around the world. In this talk, you will see and hear stories from our storytelling building, and we will discuss some of the challenges and opportunities involved in creating a permanent portfolio of content for public video walls that is crowdsourced from a campus community."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d5e1b2985-28cc-4f55-8def-2591f07c6110"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d5e1b2985-28cc-4f55-8def-2591f07c6110"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cssly"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"11/21/2014"},"content":{"type":"text","$t":"speaker: Neil Ashton, affiliation: Developer, title: Interactive Web Data Visualization for Journalism, abstract: Investigative journalism non-profit Global Witness embarked on a new experiment in 2013. Drawing on the expertise of open data non-profit Open Knowledge, Global Witness augmented four of its published reports with data visualizations and interactive graphics created with the JavaScript data visualization library D3.js – its first time incorporating interactive digital content into its work. This talk will explore the creative process and tooling behind these four projects and will give a taste of the exciting possibilities afforded to journalists by modern web technologies., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d2cb5dc17-7c80-4262-afb0-6339a46a644e, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d2cb5dc17-7c80-4262-afb0-6339a46a644e"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cssly"}],"gsx$date":{"$t":"11/21/2014"},"gsx$speaker":{"$t":"Neil Ashton"},"gsx$affiliation":{"$t":"Developer"},"gsx$title":{"$t":"Interactive Web Data Visualization for Journalism"},"gsx$abstract":{"$t":"Investigative journalism non-profit Global Witness embarked on a new experiment in 2013. Drawing on the expertise of open data non-profit Open Knowledge, Global Witness augmented four of its published reports with data visualizations and interactive graphics created with the JavaScript data visualization library D3.js – its first time incorporating interactive digital content into its work. This talk will explore the creative process and tooling behind these four projects and will give a taste of the exciting possibilities afforded to journalists by modern web technologies."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d2cb5dc17-7c80-4262-afb0-6339a46a644e"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d2cb5dc17-7c80-4262-afb0-6339a46a644e"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cu76f"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"11/28/2014"},"content":{"type":"text","$t":"speaker: No talk, affiliation: Thanksgiving Break"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cu76f"}],"gsx$date":{"$t":"11/28/2014"},"gsx$speaker":{"$t":"No talk"},"gsx$affiliation":{"$t":"Thanksgiving Break"},"gsx$title":{"$t":""},"gsx$abstract":{"$t":""},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cvlqs"},"updated":{"$t":"2015-12-11T12:54:10.655Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"12/5/2014"},"content":{"type":"text","$t":"speaker: Joseph J LaViola Jr, affiliation: University of Central Florida EECS, title: Intelligent Tutoring Interfaces with Mathematical Sketching, abstract: Using pen- and touch-based interfaces shows great potential for supporting interactive intelligent tutoring systems in a variety of different STEM disciplines.  In STEM, communication of ideas is often performed with 2D languages (e.g., mathematical expressions, diagrams) and pen and touch input provide a natural means to enter this information into a computer because of the interface's similarity to pen and paper.  Mathematical sketching is an interaction paradigm that associates handwritten, recognized mathematics and drawings together to create animations and visualizations of STEM concepts that can be used as part of intelligent tutoring systems. In this talk, I will discuss recent work on mathematical sketching and present three different application prototypes that focus on understanding of elementary data structures in computer science and set proof problems in discrete mathematics as well as answer verification through animation in introductory physics courses., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d9ae0ebad-9490-44cf-a112-f7cd87db8955, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d9ae0ebad-9490-44cf-a112-f7cd87db8955"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/odb/public/values/cvlqs"}],"gsx$date":{"$t":"12/5/2014"},"gsx$speaker":{"$t":"Joseph J LaViola Jr"},"gsx$affiliation":{"$t":"University of Central Florida EECS"},"gsx$title":{"$t":"Intelligent Tutoring Interfaces with Mathematical Sketching"},"gsx$abstract":{"$t":"Using pen- and touch-based interfaces shows great potential for supporting interactive intelligent tutoring systems in a variety of different STEM disciplines.  In STEM, communication of ideas is often performed with 2D languages (e.g., mathematical expressions, diagrams) and pen and touch input provide a natural means to enter this information into a computer because of the interface's similarity to pen and paper.  Mathematical sketching is an interaction paradigm that associates handwritten, recognized mathematics and drawings together to create animations and visualizations of STEM concepts that can be used as part of intelligent tutoring systems. In this talk, I will discuss recent work on mathematical sketching and present three different application prototypes that focus on understanding of elementary data structures in computer science and set proof problems in discrete mathematics as well as answer verification through animation in introductory physics courses."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d9ae0ebad-9490-44cf-a112-f7cd87db8955"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d9ae0ebad-9490-44cf-a112-f7cd87db8955"}}]}});
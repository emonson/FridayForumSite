// API callback
Tabletop.singleton.loadSheet({"version":"1.0","encoding":"UTF-8","feed":{"xmlns":"http://www.w3.org/2005/Atom","xmlns$openSearch":"http://a9.com/-/spec/opensearchrss/1.0/","xmlns$gsx":"http://schemas.google.com/spreadsheets/2006/extended","id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"Spring_2015"},"link":[{"rel":"alternate","type":"application/atom+xml","href":"https://docs.google.com/spreadsheets/d/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/pubhtml"},{"rel":"http://schemas.google.com/g/2005#feed","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values"},{"rel":"http://schemas.google.com/g/2005#post","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values"},{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values?alt\u003djson-in-script"}],"author":[{"name":{"$t":"eric.e.monson"},"email":{"$t":"eric.e.monson@gmail.com"}}],"openSearch$totalResults":{"$t":"14"},"openSearch$startIndex":{"$t":"1"},"entry":[{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cokwr"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"1/23/2015"},"content":{"type":"text","$t":"speaker: Angela Zoss, affiliation: Data and Visualization Services, title: Maps of Science Exhibit Tour, abstract: The first Visualization Friday Forum of 2015 will feature an introduction to the Places and Spaces: Mapping Science exhibit, which is being hosted at Duke throughout the spring semester.  After a short discussion of the history of the exhibit and the Duke venues where the maps can be found, the group will take a tour through the Edge to see 30 of the 100 maps. NOTE: Location will be the Edge, Bostock Library, 1st floor!, video: http://library.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d27de2ee4-d019-4bc7-be83-4060f3b5f81f, livestream: http://library.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d27de2ee4-d019-4bc7-be83-4060f3b5f81f"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cokwr"}],"gsx$date":{"$t":"1/23/2015"},"gsx$speaker":{"$t":"Angela Zoss"},"gsx$affiliation":{"$t":"Data and Visualization Services"},"gsx$title":{"$t":"Maps of Science Exhibit Tour"},"gsx$abstract":{"$t":"The first Visualization Friday Forum of 2015 will feature an introduction to the Places and Spaces: Mapping Science exhibit, which is being hosted at Duke throughout the spring semester.  After a short discussion of the history of the exhibit and the Duke venues where the maps can be found, the group will take a tour through the Edge to see 30 of the 100 maps. NOTE: Location will be the Edge, Bostock Library, 1st floor!"},"gsx$video":{"$t":"http://library.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d27de2ee4-d019-4bc7-be83-4060f3b5f81f"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://library.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d27de2ee4-d019-4bc7-be83-4060f3b5f81f"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cpzh4"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"1/30/2015"},"content":{"type":"text","$t":"speaker: Shane Denson, affiliation: Duke Literature, title: Visualizing Digital Seriality: Correlating Code and Community in the Super Mario Modding Scene, abstract: This presentation considers how tools and methods of digital humanities – including \"distant reading\" and visualization techniques – can shed light on serialization processes in digital games and gaming communities. The vibrant \"modding\" scene that has arisen around the classic Nintendo game Super Mario Bros. (1985) serves as a case study. Automated \"reading\" techniques allow us to survey a large collection of fan-based game modifications, while visualization software such as Tableau and Palladio help to bridge the gap between code and community, revealing otherwise invisible connections and patterns of seriality., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003de4a5e2b8-1bdd-4ad5-b734-be4bc23baf2e, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003de4a5e2b8-1bdd-4ad5-b734-be4bc23baf2e"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cpzh4"}],"gsx$date":{"$t":"1/30/2015"},"gsx$speaker":{"$t":"Shane Denson"},"gsx$affiliation":{"$t":"Duke Literature"},"gsx$title":{"$t":"Visualizing Digital Seriality: Correlating Code and Community in the Super Mario Modding Scene"},"gsx$abstract":{"$t":"This presentation considers how tools and methods of digital humanities – including \"distant reading\" and visualization techniques – can shed light on serialization processes in digital games and gaming communities. The vibrant \"modding\" scene that has arisen around the classic Nintendo game Super Mario Bros. (1985) serves as a case study. Automated \"reading\" techniques allow us to survey a large collection of fan-based game modifications, while visualization software such as Tableau and Palladio help to bridge the gap between code and community, revealing otherwise invisible connections and patterns of seriality."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003de4a5e2b8-1bdd-4ad5-b734-be4bc23baf2e"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003de4a5e2b8-1bdd-4ad5-b734-be4bc23baf2e"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cre1l"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"2/6/2015"},"content":{"type":"text","$t":"speaker: Robert Hanson, affiliation:  Dept of Chemistry, St Olaf College, title: Why Visualize? Not Just a Pretty Picture, abstract: Why do we create visualizations? Why are they important? True, there are times when we just want to have a fantastically beautiful image that Nature will choose for its cover highlighting our research and making us famous, but visualization is more than that. Visualization provides a means of organising our thoughts. Of getting our head around a subject. Of distilling the essentials out of complex information. In this presentation I will argue that visualization, insight, and discovery go hand in hand, and that pushing the boundaries of visualization can be at least as important as pushing the boundaries of science.\n\u003cp\u003e\nI am a toolmaker. I create tools that others can use in order to visualize complex molecular data. Sometimes what I am doing is just trying to do what others have done already, but within my framework; sometimes I am stretching, experimenting, trying to visualize data in ways that have not been done before. Whether it be four-dimensional crystallography, protein ligand binding, or RNA annotation, my goal is to provide new options that researchers and educators can use to gain new insights that otherwise would have been difficult to come by. In this presentation I will share a number of \"ah ha!\" moments that I and others have experienced in working with Jmol that have convinced me that good dynamic visualizations can change the way we see our work and that many interesting and valuable visualizations are still to be discovered., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d881b5e8e-3e10-46a5-b118-0e68ca6174b1, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d881b5e8e-3e10-46a5-b118-0e68ca6174b1"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cre1l"}],"gsx$date":{"$t":"2/6/2015"},"gsx$speaker":{"$t":"Robert Hanson"},"gsx$affiliation":{"$t":" Dept of Chemistry, St Olaf College"},"gsx$title":{"$t":"Why Visualize? Not Just a Pretty Picture"},"gsx$abstract":{"$t":"Why do we create visualizations? Why are they important? True, there are times when we just want to have a fantastically beautiful image that Nature will choose for its cover highlighting our research and making us famous, but visualization is more than that. Visualization provides a means of organising our thoughts. Of getting our head around a subject. Of distilling the essentials out of complex information. In this presentation I will argue that visualization, insight, and discovery go hand in hand, and that pushing the boundaries of visualization can be at least as important as pushing the boundaries of science.\n\u003cp\u003e\nI am a toolmaker. I create tools that others can use in order to visualize complex molecular data. Sometimes what I am doing is just trying to do what others have done already, but within my framework; sometimes I am stretching, experimenting, trying to visualize data in ways that have not been done before. Whether it be four-dimensional crystallography, protein ligand binding, or RNA annotation, my goal is to provide new options that researchers and educators can use to gain new insights that otherwise would have been difficult to come by. In this presentation I will share a number of \"ah ha!\" moments that I and others have experienced in working with Jmol that have convinced me that good dynamic visualizations can change the way we see our work and that many interesting and valuable visualizations are still to be discovered."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d881b5e8e-3e10-46a5-b118-0e68ca6174b1"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d881b5e8e-3e10-46a5-b118-0e68ca6174b1"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/chk2m"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"2/13/2015"},"content":{"type":"text","$t":"speaker: Cosimo Monteleone \u0026 Andrea Giordano, affiliation: University of Padua, Italy, title: New Visualization Technologies for Promoting Cultural Heritage: The Case of Eremitani Church in Padua, abstract: Promoting cultural heritage means to allow people to enjoy it properly, to allow scholars to study it scientifically and artistically and to allow restorers to secure its consistence and intelligibility through time. The first step is to survey its physical substance and new technologies, such as 3D laser scanner and digital photogrammetry, help to deal with measurements under a degree of accuracy never before achieved. The virtual clone, obtained through a cloud of points, is an exceptional digital document of the \u003cem\u003estatus quo\u003c/em\u003e, but it is also a useful tool to submit the work of art to any kind of cultural insights, such as specific interrogations, analysis of restoration, virtual travel in history and implementation of the reality. The case of Eremitani church in Padova is an extraordinary example of how creating a digital model, matched with the study and knowledge of scholars, can convey information through special visualizations., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dfebfabe0-8729-4e09-a05c-8fe14b5b0591, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dfebfabe0-8729-4e09-a05c-8fe14b5b0591"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/chk2m"}],"gsx$date":{"$t":"2/13/2015"},"gsx$speaker":{"$t":"Cosimo Monteleone \u0026 Andrea Giordano"},"gsx$affiliation":{"$t":"University of Padua, Italy"},"gsx$title":{"$t":"New Visualization Technologies for Promoting Cultural Heritage: The Case of Eremitani Church in Padua"},"gsx$abstract":{"$t":"Promoting cultural heritage means to allow people to enjoy it properly, to allow scholars to study it scientifically and artistically and to allow restorers to secure its consistence and intelligibility through time. The first step is to survey its physical substance and new technologies, such as 3D laser scanner and digital photogrammetry, help to deal with measurements under a degree of accuracy never before achieved. The virtual clone, obtained through a cloud of points, is an exceptional digital document of the \u003cem\u003estatus quo\u003c/em\u003e, but it is also a useful tool to submit the work of art to any kind of cultural insights, such as specific interrogations, analysis of restoration, virtual travel in history and implementation of the reality. The case of Eremitani church in Padova is an extraordinary example of how creating a digital model, matched with the study and knowledge of scholars, can convey information through special visualizations."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dfebfabe0-8729-4e09-a05c-8fe14b5b0591"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dfebfabe0-8729-4e09-a05c-8fe14b5b0591"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/ciyn3"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"2/20/2015"},"content":{"type":"text","$t":"speaker: Larry Carin, affiliation: Duke Office of the Vice Provost for Research, ECE, title: Visualization of Duke Research via Analysis of Faculty Publications, abstract: We will present a new interactive visualization for exploring a network of Duke authors based on data from the Scholars@Duke system, along with the novel algorithm that was used to generate the “topic model” the network is based on. The model is an automatic method for information extraction from data consisting of \"multiway\" relationships. A multiway data set consists of multiple set of entities and describes the relationships among these entities. For example, when analyzing a corpus of research publications, the multiway relationships may correspond to the co-occurrence statistics of three sets of entities – authors, words, and publication venues (e.g., author \"Alice\" used the word \"Genes\" 5 times in her papers published at venue \"Nature\"). Our method takes this multiway data and infers \"themes\" or \"topics\" in the data as well as the strength of association of entities with each of these topics. These topics can be used as attributes of the entities. For example, each author can now be described by the topics she uses the most when writing her papers. These attributes can then be used for solving various problems of interest, such as grouping authors based on the author-author similarity, or matching authors to the publication venues that they will most likely be interested in., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003db8dea5a5-81f2-4547-a5ee-0ffa0bc24286, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003db8dea5a5-81f2-4547-a5ee-0ffa0bc24286"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/ciyn3"}],"gsx$date":{"$t":"2/20/2015"},"gsx$speaker":{"$t":"Larry Carin"},"gsx$affiliation":{"$t":"Duke Office of the Vice Provost for Research, ECE"},"gsx$title":{"$t":"Visualization of Duke Research via Analysis of Faculty Publications"},"gsx$abstract":{"$t":"We will present a new interactive visualization for exploring a network of Duke authors based on data from the Scholars@Duke system, along with the novel algorithm that was used to generate the “topic model” the network is based on. The model is an automatic method for information extraction from data consisting of \"multiway\" relationships. A multiway data set consists of multiple set of entities and describes the relationships among these entities. For example, when analyzing a corpus of research publications, the multiway relationships may correspond to the co-occurrence statistics of three sets of entities – authors, words, and publication venues (e.g., author \"Alice\" used the word \"Genes\" 5 times in her papers published at venue \"Nature\"). Our method takes this multiway data and infers \"themes\" or \"topics\" in the data as well as the strength of association of entities with each of these topics. These topics can be used as attributes of the entities. For example, each author can now be described by the topics she uses the most when writing her papers. These attributes can then be used for solving various problems of interest, such as grouping authors based on the author-author similarity, or matching authors to the publication venues that they will most likely be interested in."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003db8dea5a5-81f2-4547-a5ee-0ffa0bc24286"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003db8dea5a5-81f2-4547-a5ee-0ffa0bc24286"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/ckd7g"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"2/27/2015"},"content":{"type":"text","$t":"speaker: Peter Larsen and Ryan Campbell, affiliation: Duke Biology, title: CANCELLED - Circles of Life: Visualizing biological complexity via the increased data-to-ink ratios of Circos, abstract: The Circos software package was released in 2009 and it allows for the visualization of tabular data within a circular framework. Although originally designed to visualize whole genomes and comparative genomic datasets, Circos has been used to generate  visually stunning images that help to identify patterns in complex datasets originating from almost any area of research. In the Yoder Lab our research is collectively focused on molecular evolution, however individual research interests are diverse, ranging from the natural history and phylogenetics of bats to speciation and disease surveillance of the lemurs of Madagascar. Accordingly, the datasets we have compiled are highly variable and include relatively simple tabular lists of life history traits, phylogenetic trees, genome assemblies, and complex expression data from billions of RNA sequences. For the past three years we have been using Circos to help visualize these datasets. Our presentation shares several of the Circos diagrams that we have created and is aimed at demonstrating the utility and flexibility of Circos for visualizing biological data."},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/ckd7g"}],"gsx$date":{"$t":"2/27/2015"},"gsx$speaker":{"$t":"Peter Larsen and Ryan Campbell"},"gsx$affiliation":{"$t":"Duke Biology"},"gsx$title":{"$t":"CANCELLED - Circles of Life: Visualizing biological complexity via the increased data-to-ink ratios of Circos"},"gsx$abstract":{"$t":"The Circos software package was released in 2009 and it allows for the visualization of tabular data within a circular framework. Although originally designed to visualize whole genomes and comparative genomic datasets, Circos has been used to generate  visually stunning images that help to identify patterns in complex datasets originating from almost any area of research. In the Yoder Lab our research is collectively focused on molecular evolution, however individual research interests are diverse, ranging from the natural history and phylogenetics of bats to speciation and disease surveillance of the lemurs of Madagascar. Accordingly, the datasets we have compiled are highly variable and include relatively simple tabular lists of life history traits, phylogenetic trees, genome assemblies, and complex expression data from billions of RNA sequences. For the past three years we have been using Circos to help visualize these datasets. Our presentation shares several of the Circos diagrams that we have created and is aimed at demonstrating the utility and flexibility of Circos for visualizing biological data."},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/clrrx"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"3/6/2015"},"content":{"type":"text","$t":"speaker: Christa Kelleher, affiliation: Duke Nicholas School of the Environment, title: Innovative Graphical Communication: Visualizing Scientific and Engineering Data, abstract: With the growing amount of data available at our fingertips, effective and efficient scientific visualization is becoming increasingly important in modern society. How we display data in reports, presentations, and publications and communicate our science to the public through visuals is now a more crucial skill than ever.  In this presentation we will discuss what makes an effective figure or graphic, as well as how this changes depending on the type of data being visualized and the audience/purpose the graphic is targeted at. While we generally aim for simple graphical representations, we will also touch on examples that display data in multiple dimensions and how to create simple graphics for large datasets. These ideas will be introduced in terms of a set of \"best practices\" for visualization that can be applied to any discipline. We will end with a discussion of open-source visualization tools, web-based interfaces, and analytical software to support visual analysis and presentation., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dee45ebd7-da62-4d27-8d16-5647aa167946, slides: slides/VisFriday_CKelleher.pdf, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dee45ebd7-da62-4d27-8d16-5647aa167946"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/clrrx"}],"gsx$date":{"$t":"3/6/2015"},"gsx$speaker":{"$t":"Christa Kelleher"},"gsx$affiliation":{"$t":"Duke Nicholas School of the Environment"},"gsx$title":{"$t":"Innovative Graphical Communication: Visualizing Scientific and Engineering Data"},"gsx$abstract":{"$t":"With the growing amount of data available at our fingertips, effective and efficient scientific visualization is becoming increasingly important in modern society. How we display data in reports, presentations, and publications and communicate our science to the public through visuals is now a more crucial skill than ever.  In this presentation we will discuss what makes an effective figure or graphic, as well as how this changes depending on the type of data being visualized and the audience/purpose the graphic is targeted at. While we generally aim for simple graphical representations, we will also touch on examples that display data in multiple dimensions and how to create simple graphics for large datasets. These ideas will be introduced in terms of a set of \"best practices\" for visualization that can be applied to any discipline. We will end with a discussion of open-source visualization tools, web-based interfaces, and analytical software to support visual analysis and presentation."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dee45ebd7-da62-4d27-8d16-5647aa167946"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":"slides/VisFriday_CKelleher.pdf"},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003dee45ebd7-da62-4d27-8d16-5647aa167946"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cyevm"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"3/13/2015"},"content":{"type":"text","$t":"speaker: No talk, affiliation: Spring Break"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cyevm"}],"gsx$date":{"$t":"3/13/2015"},"gsx$speaker":{"$t":"No talk"},"gsx$affiliation":{"$t":"Spring Break"},"gsx$title":{"$t":""},"gsx$abstract":{"$t":""},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":""}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cztg3"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"3/20/2015"},"content":{"type":"text","$t":"speaker: Craig Henriquez, affiliation: Duke BME, title: Visualizing Cardiac Electrophysiology from Cell to Torso, abstract: When performing simulations of complex systems, visualization of the spatio-temporal patterns is critical to uncovering the mechanisms of interest. In this talk, I will discuss our use of visualization over the years to study cardiac electrophysiology and cardiac tissue structure at multiple scales. I will present examples from both computer models and experiments ranging from conduction along strands of connected myocytes to fibrillating wavefronts on realistic atrial geometries. In each case, I will show how the visualizations have led to new insights and drove the research directions., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003ddae75202-5faf-47d2-a54b-301294665813, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003ddae75202-5faf-47d2-a54b-301294665813"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cztg3"}],"gsx$date":{"$t":"3/20/2015"},"gsx$speaker":{"$t":"Craig Henriquez"},"gsx$affiliation":{"$t":"Duke BME"},"gsx$title":{"$t":"Visualizing Cardiac Electrophysiology from Cell to Torso"},"gsx$abstract":{"$t":"When performing simulations of complex systems, visualization of the spatio-temporal patterns is critical to uncovering the mechanisms of interest. In this talk, I will discuss our use of visualization over the years to study cardiac electrophysiology and cardiac tissue structure at multiple scales. I will present examples from both computer models and experiments ranging from conduction along strands of connected myocytes to fibrillating wavefronts on realistic atrial geometries. In each case, I will show how the visualizations have led to new insights and drove the research directions."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003ddae75202-5faf-47d2-a54b-301294665813"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003ddae75202-5faf-47d2-a54b-301294665813"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/d180g"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"3/27/2015"},"content":{"type":"text","$t":"speaker: Yiyang Gong, affiliation: Duke BME, title: Toward deciphering neural codes with engineered optical voltage sensors, abstract: Studying individual neural microcircuits composed of numerous neuron types necessitates the creation of new technologies that record neural dynamics in a genetically targeted manner. Genetically encoded fluorescent voltage indicators have the potential to simultaneously report voltage waveforms from many neurons in a genetically identified population of cells. Although past probes of this class lacked the requisite kinetics, brightness, or optical response to resolve single action potentials, recently developed voltage sensors based on rhodopsin proteins exhibit high brightness and large optical responses, and provide multi-fold increases in signal-to-noise ratio. The rapid development of these indicators has enabled visualization of voltage activity in a variety of live organisms, and the imaging of single action potentials in awake behaving mammals is on the cusp experimental possibility. By applying formalisms that incorporate photon statistical noise and voltage waveforms to benchmark these various sensors, I will review the past progress of the field and describe future advancements needed to attain parallel optical recordings of voltage from many neurons. Finally, I will discuss complementary optical and signal processing methods in addition to genetically encoded sensors that will contribute to implementing voltage imaging in live-animal experiments., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d18f9ae27-8f33-4855-9eb8-36e7eb96dc22, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d18f9ae27-8f33-4855-9eb8-36e7eb96dc22"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/d180g"}],"gsx$date":{"$t":"3/27/2015"},"gsx$speaker":{"$t":"Yiyang Gong"},"gsx$affiliation":{"$t":"Duke BME"},"gsx$title":{"$t":"Toward deciphering neural codes with engineered optical voltage sensors"},"gsx$abstract":{"$t":"Studying individual neural microcircuits composed of numerous neuron types necessitates the creation of new technologies that record neural dynamics in a genetically targeted manner. Genetically encoded fluorescent voltage indicators have the potential to simultaneously report voltage waveforms from many neurons in a genetically identified population of cells. Although past probes of this class lacked the requisite kinetics, brightness, or optical response to resolve single action potentials, recently developed voltage sensors based on rhodopsin proteins exhibit high brightness and large optical responses, and provide multi-fold increases in signal-to-noise ratio. The rapid development of these indicators has enabled visualization of voltage activity in a variety of live organisms, and the imaging of single action potentials in awake behaving mammals is on the cusp experimental possibility. By applying formalisms that incorporate photon statistical noise and voltage waveforms to benchmark these various sensors, I will review the past progress of the field and describe future advancements needed to attain parallel optical recordings of voltage from many neurons. Finally, I will discuss complementary optical and signal processing methods in addition to genetically encoded sensors that will contribute to implementing voltage imaging in live-animal experiments."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d18f9ae27-8f33-4855-9eb8-36e7eb96dc22"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d18f9ae27-8f33-4855-9eb8-36e7eb96dc22"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/d2mkx"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"4/3/2015"},"content":{"type":"text","$t":"speaker: Patrick French, affiliation: Open Source Developer, title: Distributed Big Data Analysis Frameworks and Open Source Visualization Tools, abstract: Large scale distributed analysis frameworks are proliferating, but our ability to understand and interact with the output of these systems is the next frontier. Although the ecosystem is becoming richer by the day, with the increasing adoption of Hadoop, and tools it has inspired such as Storm and Spark, the challenge has become to assimilate the resulting analysis. Visualization is one of the keys to such understanding. Both batch and stream processing both present their own challenges in visualizing analysis outputs. Many complex proprietary packages exist for such visualizations, but so do capable open source tools such as D3 and WebGL. These open source tools lend themselves well to iterative and sharable explorations of data and the results of analysis. We will take a look at a few canonical data exploration problems in the light of these accessible visualization tools., videonotes: Sorry, no video for this talk, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d1bb7ccc9-99ea-4d01-a1e8-d70188386eef"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/d2mkx"}],"gsx$date":{"$t":"4/3/2015"},"gsx$speaker":{"$t":"Patrick French"},"gsx$affiliation":{"$t":"Open Source Developer"},"gsx$title":{"$t":"Distributed Big Data Analysis Frameworks and Open Source Visualization Tools"},"gsx$abstract":{"$t":"Large scale distributed analysis frameworks are proliferating, but our ability to understand and interact with the output of these systems is the next frontier. Although the ecosystem is becoming richer by the day, with the increasing adoption of Hadoop, and tools it has inspired such as Storm and Spark, the challenge has become to assimilate the resulting analysis. Visualization is one of the keys to such understanding. Both batch and stream processing both present their own challenges in visualizing analysis outputs. Many complex proprietary packages exist for such visualizations, but so do capable open source tools such as D3 and WebGL. These open source tools lend themselves well to iterative and sharable explorations of data and the results of analysis. We will take a look at a few canonical data exploration problems in the light of these accessible visualization tools."},"gsx$video":{"$t":""},"gsx$videonotes":{"$t":"Sorry, no video for this talk"},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d1bb7ccc9-99ea-4d01-a1e8-d70188386eef"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cssly"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"4/10/2015"},"content":{"type":"text","$t":"speaker: Guillermo Sapiro, affiliation: Duke ECE, iiD, title: A burst is worth a thousand kernels: A new way of image and video blind deblurring, abstract: Numerous recent approaches attempt to remove image blur due to camera shake, either with one or multiple input images, by explicitly solving an inverse and inherently ill-posed deconvolution problem. If the photographer takes a burst of images, a modality available in virtually all modern digital cameras, we show that it is possible to combine them to get a clean sharp version. This is done without explicitly solving any blur estimation and subsequent inverse problem. The proposed algorithm is strikingly simple: it performs a weighted average in the Fourier domain, with weights depending on the Fourier spectrum magnitude. The method’s rationale is that camera shake has a random nature and therefore each image in the burst is generally blurred differently. Experiments with real camera data, and extensive comparisons, show that the proposed Fourier Burst Accumulation (FBA) algorithm achieves state-of-the-art results an order of magnitude faster, with simplicity for on-board implementation on camera phones. Finally, we also present experiments in real high dynamic range (HDR) scenes, showing how the method can be straightforwardly extended to HDR photography and videos. This is joint work with Mauricio Delbracio., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d20a24476-d209-49f2-ad3d-da274e1a2bf4, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d20a24476-d209-49f2-ad3d-da274e1a2bf4"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cssly"}],"gsx$date":{"$t":"4/10/2015"},"gsx$speaker":{"$t":"Guillermo Sapiro"},"gsx$affiliation":{"$t":"Duke ECE, iiD"},"gsx$title":{"$t":"A burst is worth a thousand kernels: A new way of image and video blind deblurring"},"gsx$abstract":{"$t":"Numerous recent approaches attempt to remove image blur due to camera shake, either with one or multiple input images, by explicitly solving an inverse and inherently ill-posed deconvolution problem. If the photographer takes a burst of images, a modality available in virtually all modern digital cameras, we show that it is possible to combine them to get a clean sharp version. This is done without explicitly solving any blur estimation and subsequent inverse problem. The proposed algorithm is strikingly simple: it performs a weighted average in the Fourier domain, with weights depending on the Fourier spectrum magnitude. The method’s rationale is that camera shake has a random nature and therefore each image in the burst is generally blurred differently. Experiments with real camera data, and extensive comparisons, show that the proposed Fourier Burst Accumulation (FBA) algorithm achieves state-of-the-art results an order of magnitude faster, with simplicity for on-board implementation on camera phones. Finally, we also present experiments in real high dynamic range (HDR) scenes, showing how the method can be straightforwardly extended to HDR photography and videos. This is joint work with Mauricio Delbracio."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d20a24476-d209-49f2-ad3d-da274e1a2bf4"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003d20a24476-d209-49f2-ad3d-da274e1a2bf4"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cu76f"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"4/17/2015"},"content":{"type":"text","$t":"speaker: Regis Kopper \u0026 David Zielinski, affiliation: Duke DiVE, title: What's been happening in the DiVE, abstract: The DiVE (Duke immersive Virtual Environment) came online at Duke in 2005. Thanks to an NSF instrumentation grant we have recently completed a large hardware upgrade of the DiVE. We will discuss the new upgrades and how this will improve the user experience. We will then discuss several of our projects that we have presented at conferences in the last year (landscape archeology, training fidelity, visual persistence, and sonifications cues), along with several ongoing projects., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003defbeba43-6246-4b83-835b-694797008ffe, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003defbeba43-6246-4b83-835b-694797008ffe"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cu76f"}],"gsx$date":{"$t":"4/17/2015"},"gsx$speaker":{"$t":"Regis Kopper \u0026 David Zielinski"},"gsx$affiliation":{"$t":"Duke DiVE"},"gsx$title":{"$t":"What's been happening in the DiVE"},"gsx$abstract":{"$t":"The DiVE (Duke immersive Virtual Environment) came online at Duke in 2005. Thanks to an NSF instrumentation grant we have recently completed a large hardware upgrade of the DiVE. We will discuss the new upgrades and how this will improve the user experience. We will then discuss several of our projects that we have presented at conferences in the last year (landscape archeology, training fidelity, visual persistence, and sonifications cues), along with several ongoing projects."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003defbeba43-6246-4b83-835b-694797008ffe"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003defbeba43-6246-4b83-835b-694797008ffe"}},{"id":{"$t":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cvlqs"},"updated":{"$t":"2016-07-28T13:41:55.267Z"},"category":[{"scheme":"http://schemas.google.com/spreadsheets/2006","term":"http://schemas.google.com/spreadsheets/2006#list"}],"title":{"type":"text","$t":"4/24/2015"},"content":{"type":"text","$t":"speaker: Anastasia Deckard, affiliation: Duke Math, title: Creating Sparklines in R, abstract: Sparklines are very small plots of time series data that usually omit axes and labels. They can be combined with text, tables, or other graphics to present a high density of information while minimizing visual distraction. Our group uses sparklines for visualizing times series of gene expression data from microarrays, which provide data for thousands of genes. This type of visualization has been especially useful for the initial exploration of these data sets, comparing different genes or experiments, and examining results from analysis on the data sets. As other tools for generating sparklines did not meet our needs, we created scripts in R. The scripts can, for example, generate data tables with time series plots, matrices of time series plots for different experiments, and plots of points instead of lines to highlight missing data. These tables and sparklines are arranged into one graphic, which can be saved as PDFs for publications or presentations., video: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003db40439e7-a7ad-4019-91b6-4d194385dc53, livestream: http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003db40439e7-a7ad-4019-91b6-4d194385dc53"},"link":[{"rel":"self","type":"application/atom+xml","href":"https://spreadsheets.google.com/feeds/list/1x_pPSVaxifb1EpqqKeQfUYyTkuVt0_7oYwqHcLhHDME/od8/public/values/cvlqs"}],"gsx$date":{"$t":"4/24/2015"},"gsx$speaker":{"$t":"Anastasia Deckard"},"gsx$affiliation":{"$t":"Duke Math"},"gsx$title":{"$t":"Creating Sparklines in R"},"gsx$abstract":{"$t":"Sparklines are very small plots of time series data that usually omit axes and labels. They can be combined with text, tables, or other graphics to present a high density of information while minimizing visual distraction. Our group uses sparklines for visualizing times series of gene expression data from microarrays, which provide data for thousands of genes. This type of visualization has been especially useful for the initial exploration of these data sets, comparing different genes or experiments, and examining results from analysis on the data sets. As other tools for generating sparklines did not meet our needs, we created scripts in R. The scripts can, for example, generate data tables with time series plots, matrices of time series plots for different experiments, and plots of points instead of lines to highlight missing data. These tables and sparklines are arranged into one graphic, which can be saved as PDFs for publications or presentations."},"gsx$video":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003db40439e7-a7ad-4019-91b6-4d194385dc53"},"gsx$videonotes":{"$t":""},"gsx$slides":{"$t":""},"gsx$slidesnotes":{"$t":""},"gsx$livestream":{"$t":"http://compsci.capture.duke.edu/Panopto/Pages/Viewer.aspx?id\u003db40439e7-a7ad-4019-91b6-4d194385dc53"}}]}});